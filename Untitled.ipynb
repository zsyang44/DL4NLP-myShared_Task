{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outer-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca3792",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a098e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_question(filename, data_path):\n",
    "    \"\"\"Read the question bank\"\"\"\n",
    "    question_dict = {}\n",
    "    with open(os.path.join(data_path, filename), 'r') as lines:\n",
    "        # lists of characters of the inflected word and the lemma\n",
    "        question_ids = []\n",
    "        questions = []\n",
    "        next(lines)\n",
    "        for line in lines:\n",
    "            if not line.strip():\n",
    "                break\n",
    "            question_id, question = line.strip().split('\\t')\n",
    "            #question_ids.append(question_id)\n",
    "            #questions.append(question)\n",
    "            question_dict[question_id] = question\n",
    "\n",
    "    return question_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb013d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_answer(filename, data_path=\"answer\"):\n",
    "    \"\"\"Read the answer\"\"\"\n",
    "    with open(os.path.join(data_path, filename), 'r') as lines:\n",
    "        test_queries = []\n",
    "        test_answers = []\n",
    "        for line in lines:\n",
    "            if not line.strip():\n",
    "                break\n",
    "            query, answer = line.strip().split('\\t')\n",
    "            test_queries.append(query.strip().split(' '))\n",
    "            test_answers.append(answer.strip().split(','))\n",
    "    return test_queries, test_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889429a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id_to_question = read_question(\"question_bank.tsv\",\"\")\n",
    "question_to_id = {v : k for k, v in id_to_question.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9682e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename, data_path, isTrain):\n",
    "    \"\"\"Read the dataset and combine queries with random clarifying questions\"\"\"\n",
    "    query_to_question = defaultdict(list)\n",
    "    if isTrain == True:\n",
    "        train_queries = []\n",
    "        clarifying_questions = []\n",
    "        with open(os.path.join(data_path, filename), 'r') as lines:\n",
    "            next(lines)\n",
    "            for line in lines:\n",
    "                if not line.strip():\n",
    "                    break\n",
    "                query, clarifying_question = line.strip().split('\\t')\n",
    "                train_queries.append(query)\n",
    "                clarifying_questions.append(clarifying_question)\n",
    "                query_to_question[query].append(clarifying_question)\n",
    "    else:\n",
    "        test_queries = []\n",
    "        with open(os.path.join(data_path, filename), 'r') as lines:\n",
    "            for line in lines:\n",
    "                if not line.strip():\n",
    "                    break\n",
    "                query = line.strip()\n",
    "                test_queries.append(query)\n",
    "        return test_queries\n",
    "\n",
    "    return train_queries, clarifying_questions, query_to_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ee4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries, clarifying_questions, query_to_question = read_dataset(\"training.tsv\", \"\", True)\n",
    "test_queries = read_dataset(\"test_set.tsv\", \"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28fb231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "237\n",
      "10727\n",
      "3033\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(test_queries))\n",
    "print(len(set(train_queries)))\n",
    "print(len(clarifying_questions))\n",
    "print(len(set(clarifying_questions)))\n",
    "if test_queries[1] in query_to_question.keys():\n",
    "    print(\"True\")\n",
    "print(len(query_to_question[train_queries[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53edf50d",
   "metadata": {},
   "source": [
    "想法1: 数据集长度就是len(clarifying_questions)\n",
    "     通过随机判断是接原有对应解释问题还是随机解释问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93bed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative samples:  5302\n",
      "['Tell me about Obama family tree.', 'Tell me about Obama family tree.', 'Tell me about Obama family tree.', 'Tell me about Obama family tree.']\n",
      "['are you interested in seeing barack obamas family', 'are you interested in learning the history of the beatles', 'do you need technical support related to your service', 'would you like to know who is currently alive from president obamas family tree']\n",
      "[0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def data_preprocessing2(train_queries, clarifying_questions, query_to_question):\n",
    "    \"\"\"Get train dataset, this method was so slow\"\"\"\n",
    "    train_sentence1 = []\n",
    "    train_sentence2 = []\n",
    "    labels = []\n",
    "    \n",
    "    count = 0\n",
    "    newlist = []\n",
    "    previous_query = \"\"\n",
    "    for (query, question) in zip(train_queries, clarifying_questions):\n",
    "        if random.random() >= 0.5:\n",
    "            train_sentence1.append(query)\n",
    "            train_sentence2.append(question)\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            train_sentence1.append(query)\n",
    "            list1 = query_to_question[query]\n",
    "            if previous_query != query :\n",
    "                newlist = [item for item in clarifying_questions if item not in list1]\n",
    "            elif labels[-1] == 0 :\n",
    "                newlist = [item for item in clarifying_questions if item not in list1]\n",
    "            sentence = random.choice(newlist)\n",
    "            train_sentence2.append(sentence)\n",
    "            count += 1\n",
    "            labels.append(1)\n",
    "        previous_query = query\n",
    "    print(\"Number of negative samples: \",count)\n",
    "    #train_input = zip(train_sentence1, train_sentence2, labels)\n",
    "    return train_sentence1, train_sentence2, labels\n",
    "\n",
    "train_sentence1, train_sentence2, labels = data_preprocessing2(train_queries, clarifying_questions, query_to_question)\n",
    "print(train_sentence1[:4])\n",
    "print(train_sentence2[:4])\n",
    "print(labels[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3644f3",
   "metadata": {},
   "source": [
    "想法2: 数据集长度就是2 * len(clarifying_questions)\n",
    "1）通过随机判断是接原有对应解释问题还是随机解释问题\n",
    "2）通过洗牌来获得消极样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a027b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(train_queries, clarifying_questions, query_to_question):\n",
    "    \"\"\"Get train dataset\"\"\"\n",
    "    train_sentence1 = []\n",
    "    train_sentence2 = []\n",
    "    shuffle_questions = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    # append positive samples\n",
    "    for (query, question) in zip(train_queries, clarifying_questions):\n",
    "        train_sentence1.append(query)\n",
    "        train_sentence2.append(question)\n",
    "        shuffle_questions.append(question)\n",
    "        # positive label is 0\n",
    "        labels.append(0)\n",
    "    # append negative samples\n",
    "    random.shuffle(shuffle_questions)\n",
    "    for (query, question) in zip(train_queries, shuffle_questions):\n",
    "        train_sentence1.append(query)\n",
    "        train_sentence2.append(question)\n",
    "        if question in query_to_question[query]:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            count += 1\n",
    "            labels.append(1)\n",
    "    print(\"Number of negative samples: \",count)\n",
    "    train_input = list(zip(train_sentence1, train_sentence2, labels))\n",
    "    return train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e6087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative samples:  10661\n"
     ]
    }
   ],
   "source": [
    "train_input = data_preprocessing(train_queries, clarifying_questions, query_to_question)\n",
    "random.shuffle(train_input)\n",
    "input_len = len(train_input)\n",
    "\n",
    "train_s1, train_s2, train_labels = zip(*(train_input[:(input_len*8) // 10]))\n",
    "dev_s1, dev_s2, dev_labels = zip(*(train_input[(input_len*8) // 10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40e219",
   "metadata": {},
   "source": [
    "实现2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c690dfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryAccuracyEvaluator, CECorrelationEvaluator, CEBinaryClassificationEvaluator\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from transformers import optimization\n",
    "import torch\n",
    "import sentence_transformers\n",
    "\n",
    "model = CrossEncoder('distilroberta-base', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eb4bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative samples:  10659\n"
     ]
    }
   ],
   "source": [
    "train_input = data_preprocessing(train_queries, clarifying_questions, query_to_question)\n",
    "random.shuffle(train_input)\n",
    "input_len = len(train_input)\n",
    "\n",
    "train_s1, train_s2, train_labels = zip(*(train_input[:(input_len*8) // 10]))\n",
    "dev_s1, dev_s2, dev_labels = zip(*(train_input[(input_len*8) // 10:]))\n",
    "\n",
    "train_samples = []\n",
    "for (s1, s2, label) in zip(train_s1, train_s2, train_labels):\n",
    "    train_samples.append(InputExample(texts=[s1, s2],label=float(label)))\n",
    "dev_samples = []\n",
    "for (s1, s2, label) in zip(dev_s1, dev_s2, dev_labels):\n",
    "    dev_samples.append(InputExample(texts=[s1, s2],label=float(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a17698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ff23a0ef4140a2905b254470cde765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8c71b5d7294c1fbf0fc084f7997783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a514628d34a54d04a9fb430471624271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918020560afe4269b2ea171f03ed6f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a225ab0c39274dcba757c5b64ff66bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ef642b581d4198baad99aef1034b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2d9223a0c54a509b0ff92a77a974d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa414724f9140b1b7c0ab35ed7ab29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec545a52ffc438da75302696b44eccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367f9d613b1f4f9d80f89ef8d5953712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00f09b9113045db9fb0bdebac0ecd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_save_path = 'result/model1-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.ContrastiveLoss(model)\n",
    "evaluator = CEBinaryClassificationEvaluator.from_input_examples(dev_samples, name='nsp_dev')#dev_s1, dev_s2, dev_labels\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          optimizer_class=optimization.AdamW,\n",
    "          optimizer_params={'lr':3e-06},\n",
    "          epochs=10,\n",
    "          warmup_steps=1000,\n",
    "          evaluator=evaluator,\n",
    "          evaluation_steps=1000,\n",
    "          save_best_model=True,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e097892f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459333488697274"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = CEBinaryAccuracyEvaluator.from_input_examples(dev_samples, name='nsp_dev')\n",
    "evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d73b326a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Tell me about Computers', 'a total cholesterol of 180 to 200 mgdl 10 to 111 mmoll or less is considered best levels between 70 and 189 mgdl 39 and 105 mmoll are most often considered too high'], ['Tell me about Computers', 'about how many years experience do you want the instructor to have'], ['Tell me about Computers', 'according to anima the bible or what other source'], ['Tell me about Computers', 'ae you looking for examples of septic system design']]\n"
     ]
    }
   ],
   "source": [
    "# 初步想法是外面再套一个循环 即list of lists， 每次就预测一个切片\n",
    "test_sentences = []\n",
    "for query in test_queries:\n",
    "    test_sentences.append([[query, question] for question in list(id_to_question.values())])\n",
    "print(test_sentences[0][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98bac5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跟下面连起来一整个循坏\n",
    "model = CrossEncoder(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ac563d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeAnswer(test_queries, test_top_50, filename, data_path=\"answer\"):\n",
    "    with open(os.path.join(data_path, filename), 'w') as f:\n",
    "        string = test_queries[0] + \"\\t\"\n",
    "\n",
    "#         for item in test_top_50:\n",
    "#             string = string + item + \",\"\n",
    "#         f.write(string[:-1]+\"\\n\")\n",
    "\n",
    "        for i, query in enumerate(test_queries):\n",
    "            string = query + \"\\t\"\n",
    "            for item in test_top_50[i]:\n",
    "                string = string + item + \",\"\n",
    "            f.write(string[:-1]+\"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "223486de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_top_50 = []\n",
    "for sentences in test_sentences:\n",
    "    top_50 = []\n",
    "    predictions = model.predict(sentences)\n",
    "    b = np.argsort(predictions)[:50]\n",
    "    for i in b:\n",
    "        top_50.append(question_to_id[sentences[i][1]])\n",
    "    test_top_50.append(top_50)\n",
    "\n",
    "# predictions = model.predict(test_sentences[0])\n",
    "# b = np.argsort(predictions)[:50]\n",
    "# top_50 = []\n",
    "# for i in b:\n",
    "#     print(question_to_id[test_sentences[0][i][1]])\n",
    "#     print(test_sentences[0][i])\n",
    "#     top_50.append(question_to_id[test_sentences[0][i][1]])\n",
    "writeAnswer(test_queries, test_top_50, \"zsyanswer-epochs10-3e06-batch40.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d051b38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what information about woman are you looking for\n",
      "why are you interested in learning more about male menopause\n",
      "are you interested in the differences between male and female menopause\n",
      "would you like the evolution of men or women\n",
      "are you looking for a playlist of mothers days songs\n",
      "are you male or female\n",
      "do you want to see images of her\n",
      "are you looking for lyrics from the songs from the music man\n",
      "would you like to know about its benefit for a pregnant woman\n",
      "do you want to listen to songs from the music man\n",
      "are you looking for a summary of the music man plot\n",
      "do you want songs that were released on mothers day in a specific year\n",
      "would you like to know about specific artists related to mothers day\n",
      "would you like a list of reviews for the film rain man\n",
      "do you have an artist that you want to hear in mothers day songs\n",
      "do you want to know about a specific person\n",
      "do you want to watch the music man film\n",
      "are you referring to the voyager 1 or voyager 2\n",
      "are you referring to the person\n",
      "do you want to know her name\n",
      "are you inquiring about mister rogers the show or mister rogers the television personality\n",
      "do you have forearm pain when extending your arm\n",
      "are you referring to a crazy person\n",
      "would you like to know what age men may start male menopause\n",
      "are you looking for the current performance of the music man\n",
      "would you like to know symptoms that are common in men or common in women\n",
      "are you trying to find videos about the music man\n",
      "male or female\n",
      "would you like to see the signs of a heart attack in women or in men\n",
      "do you want to know the symptoms of male menopause\n",
      "are you looking for information on the music man musical\n",
      "are you interested in a particular hair dye or a history of hair dye\n",
      "do you want to know the cast of the music man\n",
      "are you wanting the titles of mothers day songs\n",
      "do you have any type of asbestos in mind when you ask about the dangers of asbestos\n",
      "would you like a list of best hair dyes for type of hair\n",
      "would you like to know if there are any special considerations for expectant mothers\n",
      "are you trying to loss weight\n",
      "is there a particular gender of human\n",
      "are you referring to the movie rain man\n",
      "are you looking for a specific mothers day song\n",
      "are you looking for reviews of the music man\n",
      "would you like to know when rain man was released in theatres\n",
      "are you referring to roosevelt island in new york or theodore roosevelt island in washington dc\n",
      "are you looking for her whereabouts\n",
      "are you looking album called mothers days songs\n",
      "are you interested in a balding cure for men or women\n",
      "are you looking to buy an antenna or read more about the antenna\n",
      "do you want the name of one person\n",
      "are you looking for any specific information about the business she started\n"
     ]
    }
   ],
   "source": [
    "for i in test_top_50[-1]:\n",
    "    print(id_to_question[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ec81855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q04000\n",
      "what information about woman are you looking for\n",
      "Q00429\n",
      "are you interested in the differences between male and female menopause\n",
      "Q03113\n",
      "why are you interested in learning more about male menopause\n",
      "Q03269\n",
      "would you like the evolution of men or women\n",
      "Q00091\n",
      "are you interested in a particular hair dye or a history of hair dye\n",
      "Q03988\n",
      "are you male or female\n",
      "Q02435\n",
      "do you want to see images of her\n",
      "Q00067\n",
      "are you inquiring about mister rogers the show or mister rogers the television personality\n",
      "Q03947\n",
      "do you want to know her name\n",
      "Q00845\n",
      "are you looking for general information about teddy bears and are you looking to buy a teddy bear\n",
      "Q01891\n",
      "do you want the name of one person\n",
      "Q02690\n",
      "were you interested in how much weight people lost\n",
      "Q01539\n",
      "do you have any type of asbestos in mind when you ask about the dangers of asbestos\n",
      "Q03995\n",
      "male or female\n",
      "Q03392\n",
      "would you like to know about its benefit for a pregnant woman\n",
      "Q01279\n",
      "are you referring to the person\n",
      "Q01242\n",
      "are you referring to roosevelt island in new york or theodore roosevelt island in washington dc\n",
      "Q03169\n",
      "would you like a list of reviews for the film rain man\n",
      "Q02395\n",
      "do you want to listen to songs from the music man\n",
      "Q03967\n",
      "would you like to know where to book a holiday? what country would you like your holiday to be in\n",
      "Q01203\n",
      "are you referring to a crazy person\n",
      "Q00049\n",
      "are you curious about the size\n",
      "Q02590\n",
      "is there a particular gender of human\n",
      "Q01387\n",
      "are you trying to loss weight\n",
      "Q01542\n",
      "do you have forearm pain when extending your arm\n",
      "Q02466\n",
      "do you want to watch the music man film\n",
      "Q00115\n",
      "are you interested in a specific pose\n",
      "Q02767\n",
      "what does unc mean\n",
      "Q01152\n",
      "are you looking to dye your hair\n",
      "Q00002\n",
      "a total cholesterol of 180 to 200 mgdl 10 to 111 mmoll or less is considered best levels between 70 and 189 mgdl 39 and 105 mmoll are most often considered too high\n",
      "Q01569\n",
      "do you mean do not resuscitate\n",
      "Q01193\n",
      "are you planning to run or exercise\n",
      "Q03573\n",
      "would you like to know symptoms that are common in men or common in women\n",
      "Q00943\n",
      "are you looking for mini gastric bypass surgery\n",
      "Q01968\n",
      "do you want to know about a specific person\n",
      "Q03159\n",
      "would you like a list of best hair dyes for type of hair\n",
      "Q01921\n",
      "do you want to compare different models\n",
      "Q02519\n",
      "how fast would you like to lose weight\n",
      "Q02564\n",
      "if youre interested in recipes would you like savory or sweet receipes do you have other specific ingredients in mind\n",
      "Q03222\n",
      "would you like information about the alternatives to violence project\n",
      "Q00853\n",
      "are you looking for her whereabouts\n",
      "Q02454\n",
      "do you want to shop online for clothes\n",
      "Q02092\n",
      "do you want to know how to lose weight\n",
      "Q00937\n",
      "are you looking for lyrics from the songs from the music man\n",
      "Q02373\n",
      "do you want to learn about cervical cancer\n",
      "Q02666\n",
      "the flag has an emblem on it i can tell you what it symbolizes\n",
      "Q02998\n",
      "which age group is of more interest to you\n",
      "Q03411\n",
      "would you like to know about specific artists related to mothers day\n",
      "Q01377\n",
      "are you trying to find videos about the music man\n",
      "Q02618\n",
      "is there any specific thing that evolves that you want to learn more about its evolution\n"
     ]
    }
   ],
   "source": [
    "test_q, test_answers = read_answer(\"zsyanswer-epochs9-3e06-batch16.txt\")\n",
    "for item in test_answers[-1]:\n",
    "    print(item)\n",
    "    print(id_to_question[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "handed-summary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(tf.test.is_gpu_available())\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "    print(tf.test.gpu_device_name())\n",
    "    #print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073169d",
   "metadata": {},
   "source": [
    "实现1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e4dc6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch, gc\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a205c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(train_s1, train_s2, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8626e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = torch.LongTensor([train_labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e125cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa38a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afc7301f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73890ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88266745",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6179fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/4291 [00:00<?, ?it/s]E:\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Epoch 0: 100%|█████████████████████████████████████████████████████████| 4291/4291 [28:30<00:00,  2.51it/s, loss=0.866]\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████| 4291/4291 [1:13:06<00:00,  1.02s/it, loss=0.00776]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids,\n",
    "                       labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c58a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "211dd150",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f88e1993c62b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdev_inputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_s1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_s2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max_length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdev_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdev_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdev_outputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_s1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n...\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdev_s2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "dev_inputs =tokenizer(dev_s1[1], dev_s2[1], return_tensors='pt', max_length=512, truncation=True, padding='max_length').to(device)\n",
    "dev_outputs = model(**dev_inputs)\n",
    "dev_outputs.keys()\n",
    "print(dev_s1[1] + \"\\n...\" + dev_s2[1])\n",
    "print(dev_outputs.logits)\n",
    "torch.softmax(dev_outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e3d3a",
   "metadata": {},
   "source": [
    "分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff7440fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing TFBertForSequenceClassification: ['dropout_183']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at bert-base-cased-finetuned-mrpc.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09536304 0.904637  ]\n",
      "[0.94038326 0.05961675]\n",
      "negative: 10%\n",
      "positive: 90%\n",
      "negative: 94%\n",
      "positive: 6%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "\n",
    "classes = [\"negative\", \"positive\"]\n",
    "\n",
    "sequence_0 = \"The company HuggingFace is based in New York City\"\n",
    "sequence_1 = \"Apples are especially bad for your health\"\n",
    "sequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n",
    "\n",
    "# The tokenizer will automatically add any model specific separators (i.e. <CLS> and <SEP>) and tokens to the sequence, as well as compute the attention masks.\n",
    "paraphrase = tokenizer(sequence_0, sequence_2, return_tensors=\"tf\")\n",
    "not_paraphrase = tokenizer(sequence_0, sequence_1, return_tensors=\"tf\")\n",
    "\n",
    "paraphrase_classification_logits = model(paraphrase)[0]\n",
    "not_paraphrase_classification_logits = model(not_paraphrase)[0]\n",
    "\n",
    "paraphrase_results = tf.nn.softmax(paraphrase_classification_logits, axis=1).numpy()[0]\n",
    "not_paraphrase_results = tf.nn.softmax(not_paraphrase_classification_logits, axis=1).numpy()[0]\n",
    "print(paraphrase_results)\n",
    "print(not_paraphrase_results)\n",
    "# Should be paraphrase\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {int(round(paraphrase_results[i] * 100))}%\")\n",
    "    \n",
    "# Should not be paraphrase\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {int(round(not_paraphrase_results[i] * 100))}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
